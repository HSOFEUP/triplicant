{"tagline":"","body":"[TRIPLICANT - Travel discovery engine] (http://triplicant.heroku.com)\r\n======================================================================\r\n\r\n\r\n\r\nOverview\r\n-----------\r\nTriplicant attempts to recommend an optimal travel route given a start and end point and a \"detour factor\", which represents how much time/money/etc. you are willing to spend travelling between the ends points. It identifies popular locations and ranks them using photo metadata extracted from the Flickr API. Then it uses a genetic algorithm to approximate a solution to the \"Orienteering\" problem.\r\n \r\nTechnology\r\n--------------\r\nThis project is built primarily in Python using the Flask microframework for the web backend.I've used Postgres for the\r\ndata store and jQuery for the fancy front end with the help of Google Maps API to make sense of it all. It's currently \r\nrunning on a single dyno on Heroku so unfortunately sometimes it takes awhile to wake up.\r\n\r\n\r\nBehind the scenes\r\n--------------------\r\nTriplicant uses some interesting concepts from AI, such as:\r\n\r\n### Clustering\r\n\r\nUses a mean-shift clustering algorithm to identify about 600 clusters(locations) each with about a radius of 4 miles where many photos have been taken.\r\n\r\n### Graph centrality\r\n\r\nThe notion of centrality of a graph is a measure of a vertex's overall importance within the graph. Here I used probability of transit between two locations, after reducing a users photo history to an ordered sequence of locations they visited, combined with the total number of photos taken in a location to compute the centrality of each node in a way that is similar to the method of eigenvector centrality, in particularly the algorithm is highly influenced by Google PageRank. The set of equations for the importance of each vertex is then solved using a value iteration method.\r\n\r\n### Solving the orienteering problem via a GA\r\n\r\nAt first I had intend to use my importance values in a simple model of path cost and compute a A* graph search. However, quickly found that I was modeling problem incorrectly. After some research I found that the problem I was actually trying to solve is the point-to-point orienteering problem. My version of this problem is: \r\n\r\nGiven:\r\n* G = (V,E) is a fully connected undirected graph\r\n* let each vertex have a \"score\" associated with it (importance in this case) eg. s: V -> R\r\n* let each edge have a path cost, in this problem I've simply used the great circle distance between the locations. d : E -> R\r\n* a hard upper limit on the acceptable path cost \r\n* a start node and an end node\r\n\r\nFind:\r\n* the path from the start node to the end node that has the highest possible score of the paths with acceptable path costs, where the score of a path is the sum score of the nodes it visits\r\n\r\nOr rather, find a path that connects the start and end and visits the most interesting destinations in-between given a travel budget.\r\n\r\nUnfortunately, as this problem is reducible to a variant of the Travelling Salesman Problem it is also NP-hard and the exact solution can't be computed for a worthwhile number of nodes in a reasonable time. Thus, I've used a \"queen-bee\" genetic algorithm to approximate a solution.  The algorithm can be described as follows:\r\n\r\n1. Generate a population of random paths between the start and end using all the other nodes\r\n2. remove nodes from random points along the paths until the path cost is acceptable\r\n3. rank the population by fitness, the fittest member of the population becomes \"the queen\", the top half of the rest have a chance to crossover with the queen\r\n4. for each remaining paths, with a certain probability generate a new path by probabilistically building it out the queen's and the path's components\r\n5. for each new path, \"mutate\" with a certain probability, that is to say insert a node taken from a probability distribution where the nodes are weighed by score and insert it at a random point along the path.\r\n6. remove nodes from random points until the path cost of the new path is acceptable\r\n7. permute each path to see if a different ordering would have a lower path cost\r\n8. repeat 3-7 for a given number of iterations(generations) and return the queen of the last generation\r\n\r\nInnovation\r\n---------------\r\n\r\nTriplicant builds on some existing research in various fields of AI and combines them in a novel way. As far as I know Triplicant is the first app of its kind to:\r\n\r\n* apply clustering to identify locations from photo metadata on a global scale\r\n* attempt to weight travel destinations by computing their centrality within a graph\r\n* apply a GA to this instance of the orienteering problem\r\n* combine the above ideas to try to produce travel routes\r\n\r\n\r\nFuture\r\n------------\r\n\r\nRight now Triplicant is somewhat limited by the data it has to work with. The location ranking algorithm currently only \r\nworks on about 150K photos from 3000 unique Flickr users to extract information. This data also has a strong bias to the\r\nUK for some reason. I believe that expanding the data set to \"smooth\" out the statistics would greatly improve the results\r\nof the ranking algorithm.\r\n\r\nI'm also looking forward to improving the app by using a better metric of travel time between locations than simply the \r\ngreat circle distance. There are also plans to incorporate data from other API to recommend individual sites of interest\r\nnear each destination along the trip.\r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration.","name":"Triplicant"}